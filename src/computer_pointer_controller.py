'''
--------------------------------------------------------------------------------

MIT License

Copyright (c) 2020 Marcin Sielski

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

--------------------------------------------------------------------------------
'''

# %%
'''
Import and initialize Line Profiler
''' 

import line_profiler
profiler = line_profiler.LineProfiler()
import atexit

# %%
'''
Import all the required modules
'''

from argparse import ArgumentParser, ArgumentTypeError
from mouse_controller import MouseController
import input_feeder
from face_detection import ModelFaceDetection
from facial_landmarks_detection import ModelFacialLandmarksDetection
from gaze_estimation import ModelGazeEstimation
from head_pose_estimation import ModelHeadPoseEstimation
from input_feeder import InputFeeder
import cv2
from multiprocessing import Pool
import logging
import numpy as np
import math
from pynput import keyboard
import time

# %%
'''
Define ComputerPointerController class
'''

class ComputerPointerController:

    '''
    ComputerPointerController class defines all the methods necessary to enable
    control of computer pointer
    '''

    def __init__(self):

        '''
        Initialize computer pointer controller
        '''

        self.execute = True
        self.debug = False


    def parse(self):

        '''
        Creates parser object input arguments

        Returns:
            ArgumentParser: argument parser object
        '''        

        parser = ArgumentParser()
        parser.add_argument('-i', '--input', required=True, type=str,
                            help='select input path to the image or video '
                            'file or specify camera pipeline')
        parser.add_argument('-o', '--output', type=str, help='specify the '
                            'file where to store image generated by -g 1234')
        parser.add_argument('-d', '--device', type=str, default='CPU',
                            help='specify the target device for selected '
                            'model to infer on to get performance gain: CPU, '
                            'GPU, FPGA or MYRIAD (CPU by default). Most '
                            'of the models must be run on CPU anyway')
        parser.add_argument('-g', '--debug', type=str, nargs='?', \
                            const='1', default='', help='enable debug mode '
                            'for specified models (1 by default): '
                            '1 - face detection (mandatory), '
                            '2 - head pose estimation (optional), '
                            '3 - facial landmarks detection (optional), '
                            '4 - gaze estimation (optional)')
        parser.add_argument('-p', '--profiler', nargs='?', \
                            const=True, default=False, help='enable profiler '
                            '(False by default)')
        parser.add_argument('-q', '--precision', type=str, nargs='?', \
                            const='FP32-INT8', default='FP32', \
                            help='force to use selected '
                            'precision for some models (FP32-INT8 by default): '
                            'FP16 - half precision floating point format, '
                            'FP32 - single precision floating point format, '
                            'FP32-INT8 - 8-bit precision integer format.')
        parser.add_argument('-l', '--loglevel', nargs='?', \
                            const='INFO', default='WARNING', help='enable log '
                            'level (INFO by default): NOTSET, DEBUG, INFO, '
                            'WARNING, ERROR, CRITICAL')
        parser.add_argument('-s', '--silent', nargs='?', \
                            const=True, default=False, help='enable silent mode'
                            ' (False by default)')
        return parser


    def axises(self, image, rotation):

        '''
        Draws axises defined by the rotation angles on the specified image

        Args:
            image (ndarray): image to draw on
            rotation (ndarray): vector with euler angles

        Returns:
            ndarray: image with drawn axises
        '''

        focal_length = image.shape[1]
        center = (image.shape[1]/2, image.shape[0]/2)
        camera_matrix = np.float32([[focal_length, 0, center[0]], \
            [0, focal_length, center[1]], [0, 0, 1]])
        r = np.float32([[math.radians(-rotation[0]), math.radians(rotation[2]),\
            math.radians(rotation[1])]])
        points = np.float32([[5, 0, 0], [0, 5, 0], [0, 0, 5], [0, 0, 0]])
        axis, _ = cv2.projectPoints(points, r, np.float32([0, 0, 0]), \
            camera_matrix, np.zeros((4,1)))
        image = cv2.line(image, (int(axis[3].ravel()[0]), \
            int(axis[3].ravel()[1])), (int(axis[0].ravel()[0]), \
                int(axis[0].ravel()[1])), (255,0,0), 3)
        image = cv2.line(image, (int(axis[3].ravel()[0]), \
            int(axis[3].ravel()[1])), (int(axis[1].ravel()[0]), \
                int(axis[1].ravel()[1])), (0,255,0), 3)
        image = cv2.line(image, (int(axis[3].ravel()[0]), \
            int(axis[3].ravel()[1])), (int(axis[2].ravel()[0]), \
                int(axis[2].ravel()[1])), (0,0,255), 3)
        return image


    def points(self, image, coordinates):

        '''
        Draws points defined by coordinates on the specified image

        Args:
            image (ndarray): image to draw on
            coordinates (ndarray): vector with point coordinates

        Returns:
            ndarray: image with drawn points
        '''

        for coordinate in coordinates:
            cv2.circle(image, coordinate, 5, (0,255,255), -1)
        return image


    def lines(self, image, vector):

        '''
        Draws lines defined by vector on the specified image

        Args:
            image (ndarray): image to draw on
            vector (ndarray): vector to draw

        Returns:
            ndarray: image with drawn lines
        '''

        focal_length = image.shape[1]
        center = (image.shape[1]/2, image.shape[0]/2)
        camera_matrix = np.float32([[focal_length, 0, center[0]], \
            [0, focal_length, center[1]], [0, 0, 1]])
        points = np.float32([[-vector[0], vector[1], vector[2]], [0,0,0]])
        line, _ = cv2.projectPoints(points, np.float32([0, 0, 0]), \
            np.float32([0, 0, 0]), camera_matrix, np.zeros((4,1)))
        image = cv2.line(image, (int(line[1].ravel()[0]), \
            int(line[1].ravel()[1])), (int(line[0].ravel()[0]), \
                int(line[0].ravel()[1])), (255,0,255), 3)
        return image


    def on_release(self, key):

        '''
        Callback handler executed on key release used to terminate the
        application

        Args:
            key (Key): released key code

        Returns:
            bool: ``False`` in case ``esc`` key was released
        '''

        if key == keyboard.Key.esc:
            if not self.debug:
                print('')
            self.execute = False
            return False


    @profiler
    def run(self, args):
        
        '''
        Runs inference on specified input

        Args:
            args (Namespace): application arguments
        '''
        listener = keyboard.Listener(on_release=self.on_release)
        listener.start()
        if args.debug is not '':
            self.debug = True
        if not args.silent and args.debug is '':
            print('Press \'esc\' to exit')
        mouseController = MouseController('high','fast')
        mouseController.center()
        inputFeeder = InputFeeder(args.input)
        logging.info('Loading models')
        start_loading = time.time()
# ----- Models Load ------------------------------------------------------------
        faceDetection = ModelFaceDetection()
        facialLanmarksDetection = ModelFacialLandmarksDetection(precision=args.precision)
        headPoseEstimation = ModelHeadPoseEstimation(device=args.device, precision=args.precision)
        gazeEstimation = ModelGazeEstimation(precision=args.precision)
# ------------------------------------------------------------------------------
        stop_loading = time.time()
        loading_time = stop_loading - start_loading
        pool = Pool(processes=1) # Must be called after Models Load
        logging.info('Starting inference')
        frame = None
        image = None
        inference_time = 0
        counter = 0
        while self.execute:
            try:
                frame = next(inputFeeder.next_batch())
            except StopIteration:
                logging.error('Failed to obtain input stream.')
                break
            if frame is None:
                break
            start_inference = time.time()
# ----- Inference --------------------------------------------------------------
            faceDetection.inputs(frame) # GFlops 0.611
            faceDetection.wait()
            outputs = faceDetection.outputs()
            if len(outputs) == 0:
                logging.warning('No face detected')
                continue
            if len(outputs) > 1:
                logging.warning('More then one face detected')
            if outputs[0].shape[0] == 0 or outputs[0].shape[1] == 0 or \
                outputs[0].shape[2] < 3:
                logging.warning('Image too small')
                continue

            headPoseEstimation.inputs(outputs[0]) # GFlops 0.105
            facialLanmarksDetection.inputs(outputs[0]) # GFlops 0.021
        
            facialLanmarksDetection.wait()
            outputs = facialLanmarksDetection.outputs()
            if outputs[0].shape[0] < 60 or outputs[0].shape[1] < 60 or \
                outputs[0].shape[2] < 3 or outputs[1].shape[0] < 60 or \
                outputs[1].shape[1] < 60 or outputs[1].shape[2] < 3:
                logging.warning('Image too small')
                continue
            headPoseEstimation.wait()
            outputs.append(headPoseEstimation.outputs())

            gazeEstimation.inputs(outputs) # GFlops 0.139
            gazeEstimation.wait()
            outputs = gazeEstimation.outputs()
# ------------------------------------------------------------------------------
            stop_inference = time.time()
            result = pool.apply_async(mouseController.move,[outputs[0], \
                outputs[1]])
            inference_time = inference_time + stop_inference - start_inference
            counter = counter + 1
            if '1' in args.debug:
                image = faceDetection.debug[0]
                if '2' in args.debug:
                    self.axises(image, headPoseEstimation.debug)
                if '3' in args.debug:
                    self.points(image, facialLanmarksDetection.debug)
                if '4' in args.debug:
                    self.lines(image, gazeEstimation.debug)
                cv2.imshow('Debug Mode (Press \'esc\' to exit)', image)
                cv2.waitKey(50)
            if args.output is not None:
                image = faceDetection.debug[0]
                self.axises(image, headPoseEstimation.debug)
                self.points(image, facialLanmarksDetection.debug)
                self.lines(image, gazeEstimation.debug)
        inputFeeder.close()
        if args.output is not None:
            cv2.imwrite(args.output, image)
        if not args.silent:
            print('Total loading time of the models: ' + str(loading_time) + ' s')
            print('Average inference time: ' + str(inference_time/counter) + ' s')
            print('Frames per second: ' + str(counter/inference_time))

# %%
'''
Run application
'''

if __name__ == "__main__":
    main = ComputerPointerController()
    args = main.parse().parse_args()
    logging.basicConfig(format='%(asctime)s %(levelname)s: %(message)s', \
        level=getattr(logging, args.loglevel.upper()))
    logging.info(args)
    if args.profiler:
        atexit.register(profiler.print_stats)
    main.run(args)
